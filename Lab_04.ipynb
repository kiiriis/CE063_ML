{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMy8Cfja7Dhc3r1688ZB3g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiiriis/CE063_ML/blob/main/Lab_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4_0"
      ],
      "metadata": {
        "id": "l-MmKKnIs4MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Input (temp, rainfall, humidity)\n",
        "input = np.array([[73, 67, 43],\n",
        "[91, 88, 64],\n",
        "[87, 134, 58],\n",
        "[102, 43, 37],\n",
        "[69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56],\n",
        "[81],\n",
        "[119],\n",
        "[22],\n",
        "[103]], dtype='float32')\n",
        "\n",
        "# generate model\n",
        "\n",
        "initial_target=np.array([[100],\n",
        "[100],\n",
        "[80],\n",
        "[90],\n",
        "[100]], dtype='float32') # taking random values\n",
        "\n",
        "weight = np.array([[10],\n",
        "[20],\n",
        "[15],\n",
        "[11],\n",
        "[30]], dtype='float32')\n",
        "\n",
        "bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n",
        "\n",
        "# Generate predictions\n",
        "\n",
        "prediction = (initial_target*weight) + bias\n",
        "\n",
        "  # print(prediction)\n",
        "\n",
        "# MSE loss\n",
        "  # from sklearn.metrics import mean_squared_error\n",
        "  # x=mean_squared_error(target,prediction)\n",
        "  # print(x)\n",
        "\n",
        "# import numpy as np\n",
        "# MSE = np.square(np.subtract(target,prediction)).mean()\n",
        "# print(MSE)"
      ],
      "metadata": {
        "id": "X0S4UZmcECO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Gradients\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "  # print(inputs)\n",
        "  # print(targets)\n",
        "dataset = TensorDataset(inputs,targets)\n",
        "  # print(dataset[:5])\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Adjust weights and biases using gradient descent\n",
        "weights= torch.randn(1,3, requires_grad=True)\n",
        "biass = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(weights)\n",
        "print(biass)\n",
        "\n",
        "def model(X):\n",
        "  return X @ weights.t() + biass  # '@' - for matrix multiplication\n",
        "\n",
        "for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    print(\"Prediction is :\\n\",preds)\n",
        "    print(\"\\nActual targets is :\\n\",y)\n",
        "    break\n",
        "\n",
        "# Calculate the loss\n",
        "def mse_loss(predictions, targets):\n",
        "  difference = predictions - targets\n",
        "  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds=model(x)\n",
        "  print(\"Prediction is :\\n\", preds)\n",
        "  print(\"\\nActual targets is :\\n\",y)\n",
        "  print(\"\\nLoss is: \",mse_loss(preds,y))\n",
        "  break\n",
        "\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "    # Iterate through training dataloader\n",
        "    for x,y in train_loader:\n",
        "        # Generate Prediction\n",
        "        preds = model(x)\n",
        "\n",
        "        # Get the loss and perform backpropagation\n",
        "        loss = mse_loss(preds, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Let's update the weights\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad *1e-5\n",
        "            biass -= biass.grad * 1e-5\n",
        "            # Set the gradients to zero\n",
        "            weights.grad.zero_()\n",
        "            biass.grad.zero_()\n",
        "    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds= model(x)\n",
        "  print(\"\\nFinal Prediction is :\\n\",preds)\n",
        "  print(\"\\nActual targets are :\\n\",y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvYLMeTCElg6",
        "outputId": "7285d907-bfa2-4772-e7e4-852467f325d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1999,  0.1494, -0.7254]], requires_grad=True)\n",
            "tensor([-0.7655], requires_grad=True)\n",
            "Prediction is :\n",
            " tensor([[-52.2376],\n",
            "        [-50.9978],\n",
            "        [-40.2140],\n",
            "        [-36.5425]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[ 81.],\n",
            "        [103.],\n",
            "        [119.],\n",
            "        [ 56.]])\n",
            "Prediction is :\n",
            " tensor([[-41.5715],\n",
            "        [-36.5425],\n",
            "        [-40.2140],\n",
            "        [-52.2376]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[ 22.],\n",
            "        [ 56.],\n",
            "        [119.],\n",
            "        [ 81.]])\n",
            "\n",
            "Loss is:  tensor(13926.7061, grad_fn=<DivBackward0>)\n",
            "\n",
            "Final Prediction is :\n",
            " tensor([[118.5108],\n",
            "        [ 20.9682],\n",
            "        [101.2231],\n",
            "        [ 56.7800]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets are :\n",
            " tensor([[119.],\n",
            "        [ 22.],\n",
            "        [103.],\n",
            "        [ 56.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights)\n",
        "print(biass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pph9TR-pEmsw",
        "outputId": "abe98f0a-657c-4982-bebc-23a9c8f889d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3903,  0.8523,  0.6728]], requires_grad=True)\n",
            "tensor([-0.7583], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Use the model to predict crop yield for apples if temperature is 70, Rain is 34 and Humidity is 45.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(inputs, targets)\n",
        "\n",
        "# for x,y in dataset:\n",
        "#   print(x,y)\n",
        "\n",
        "test_input = np.array([[70, 34, 45]])\n",
        "\n",
        "y_pred = model.predict(test_input)\n",
        "print(\"Prediction: \", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzgbm4otFAIu",
        "outputId": "417c2f4d-b2ee-4c7e-9fdd-e69998524665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  [[31.47395247]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Estimate the value of model parameters(weights and bias) and MSE Loss after training for 1000 epochs.\n",
        "import numpy as np\n",
        "MSE = mse_loss(preds,y)\n",
        "print(\"MSE: \",MSE)\n",
        "\n",
        "print(\"Weights: \",weights)\n",
        "print(\"Bias: \",biass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLYWv18zFBR4",
        "outputId": "0bfb80a6-f09a-4b19-91a5-3c71a6545d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  tensor(1.2674, grad_fn=<DivBackward0>)\n",
            "Weights:  tensor([[-0.3903,  0.8523,  0.6728]], requires_grad=True)\n",
            "Bias:  tensor([-0.7583], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Take the learning rate value as 0.1 and train the model. Write in brief the impact of this learning rate on the model.\n",
        "# Compute Gradients\n",
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Input (temp, rainfall, humidity)\n",
        "input = np.array([[73, 67, 43],\n",
        "[91, 88, 64],\n",
        "[87, 134, 58],\n",
        "[102, 43, 37],\n",
        "[69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56],\n",
        "[81],\n",
        "[119],\n",
        "[22],\n",
        "[103]], dtype='float32')\n",
        "\n",
        "# generate model\n",
        "\n",
        "initial_target=np.array([[100],\n",
        "[100],\n",
        "[80],\n",
        "[90],\n",
        "[100]], dtype='float32') # taking random values\n",
        "\n",
        "weight = np.array([[10],\n",
        "[20],\n",
        "[15],\n",
        "[11],\n",
        "[30]], dtype='float32')\n",
        "\n",
        "bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n",
        "\n",
        "# Generate predictions\n",
        "\n",
        "prediction = (initial_target*weight) + bias\n",
        "\n",
        "  # print(prediction)\n",
        "\n",
        "# MSE loss\n",
        "  # from sklearn.metrics import mean_squared_error\n",
        "  # x=mean_squared_error(target,prediction)\n",
        "  # print(x)\n",
        "\n",
        "# import numpy as np\n",
        "# MSE = np.square(np.subtract(target,prediction)).mean()\n",
        "# print(MSE)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "  # print(inputs)\n",
        "  # print(targets)\n",
        "dataset = TensorDataset(inputs,targets)\n",
        "  # print(dataset[:5])\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Adjust weights and biases using gradient descent\n",
        "weights= torch.randn(1,3, requires_grad=True)\n",
        "biass = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(weights)\n",
        "print(biass)\n",
        "\n",
        "def model(X):\n",
        "  return X @ weights.t() + biass  # '@' - for matrix multiplication\n",
        "\n",
        "for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    print(\"Prediction is :\\n\",preds)\n",
        "    print(\"\\nActual targets is :\\n\",y)\n",
        "    break\n",
        "\n",
        "# Calculate the loss\n",
        "def mse_loss(predictions, targets):\n",
        "  difference = predictions - targets\n",
        "  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds=model(x)\n",
        "  print(\"Prediction is :\\n\", preds)\n",
        "  print(\"\\nActual targets is :\\n\",y)\n",
        "  print(\"\\nLoss is: \",mse_loss(preds,y))\n",
        "  break\n",
        "\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "    # Iterate through training dataloader\n",
        "    for x,y in train_loader:\n",
        "        # Generate Prediction\n",
        "        preds = model(x)\n",
        "\n",
        "        # Get the loss and perform backpropagation\n",
        "        loss = mse_loss(preds, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Let's update the weights\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad *0.1\n",
        "            biass -= biass.grad * 0.1\n",
        "            # Set the gradients to zero\n",
        "            weights.grad.zero_()\n",
        "            biass.grad.zero_()\n",
        "    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds= model(x)\n",
        "  print(\"\\nFinal Prediction is :\\n\",preds)\n",
        "  print(\"\\nActual targets are :\\n\",y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwx14IIJFCgq",
        "outputId": "c87231b0-0709-4365-95b6-71f7be1477c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1537,  0.0148,  3.0292]], requires_grad=True)\n",
            "tensor([0.4066], requires_grad=True)\n",
            "Prediction is :\n",
            " tensor([[164.7096],\n",
            "        [120.4337],\n",
            "        [203.2660],\n",
            "        [181.5914]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[119.],\n",
            "        [ 56.],\n",
            "        [103.],\n",
            "        [ 81.]])\n",
            "Prediction is :\n",
            " tensor([[164.7096],\n",
            "        [203.2660],\n",
            "        [ 97.4471],\n",
            "        [181.5914]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[119.],\n",
            "        [103.],\n",
            "        [ 22.],\n",
            "        [ 81.]])\n",
            "\n",
            "Loss is:  tensor(6988.3843, grad_fn=<DivBackward0>)\n",
            "\n",
            "Final Prediction is :\n",
            " tensor([[nan],\n",
            "        [nan],\n",
            "        [nan],\n",
            "        [nan]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets are :\n",
            " tensor([[119.],\n",
            "        [ 81.],\n",
            "        [ 22.],\n",
            "        [103.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "MSE = mse_loss(preds,y)\n",
        "print(\"MSE: \",MSE)\n",
        "\n",
        "print(\"Weights: \",weights)\n",
        "print(\"Bias: \",biass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Uiygs9UlFD82",
        "outputId": "941ac1e6-0829-46e5-cf01-851303b58d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b8636ea0eda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-5e99b0430f90>\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(predictions, targets)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m   \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# numel() method returns the number of elements in the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Take the learning rate value as 0.0000001 and train the model. Write in brief the impact of this learning rate on the model.\n",
        "# Compute Gradients\n",
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Input (temp, rainfall, humidity)\n",
        "input = np.array([[73, 67, 43],\n",
        "[91, 88, 64],\n",
        "[87, 134, 58],\n",
        "[102, 43, 37],\n",
        "[69, 96, 70]], dtype='float32')\n",
        "\n",
        "target = np.array([[56],\n",
        "[81],\n",
        "[119],\n",
        "[22],\n",
        "[103]], dtype='float32')\n",
        "\n",
        "# generate model\n",
        "\n",
        "initial_target=np.array([[100],\n",
        "[100],\n",
        "[80],\n",
        "[90],\n",
        "[100]], dtype='float32') # taking random values\n",
        "\n",
        "weight = np.array([[10],\n",
        "[20],\n",
        "[15],\n",
        "[11],\n",
        "[30]], dtype='float32')\n",
        "\n",
        "bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n",
        "\n",
        "# Generate predictions\n",
        "\n",
        "prediction = (initial_target*weight) + bias\n",
        "loss_arr=[];\n",
        "  # print(prediction)\n",
        "\n",
        "# MSE loss\n",
        "  # from sklearn.metrics import mean_squared_error\n",
        "  # x=mean_squared_error(target,prediction)\n",
        "  # print(x)\n",
        "\n",
        "# import numpy as np\n",
        "# MSE = np.square(np.subtract(target,prediction)).mean()\n",
        "# print(MSE)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(inputs, targets, random_state=97)\n",
        "\n",
        "  # print(inputs)\n",
        "  # print(targets)\n",
        "dataset = TensorDataset(inputs,targets)\n",
        "  # print(dataset[:5])\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Adjust weights and biases using gradient descent\n",
        "weights= torch.randn(1,3, requires_grad=True)\n",
        "biass = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(weights)\n",
        "print(biass)\n",
        "\n",
        "def model(X):\n",
        "  return X @ weights.t() + biass  # '@' - for matrix multiplication\n",
        "\n",
        "for x,y in train_loader:\n",
        "    preds = model(x)\n",
        "    print(\"Prediction is :\\n\",preds)\n",
        "    print(\"\\nActual targets is :\\n\",y)\n",
        "    break\n",
        "\n",
        "# Calculate the loss\n",
        "def mse_loss(predictions, targets):\n",
        "  difference = predictions - targets\n",
        "  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds=model(x)\n",
        "  print(\"Prediction is :\\n\", preds)\n",
        "  print(\"\\nActual targets is :\\n\",y)\n",
        "  print(\"\\nLoss is: \",mse_loss(preds,y))\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "    # Iterate through training dataloader\n",
        "    for x,y in train_loader:\n",
        "        # Generate Prediction\n",
        "        preds = model(x)\n",
        "\n",
        "        # Get the loss and perform backpropagation\n",
        "        \n",
        "        loss = mse_loss(preds, y)\n",
        "        loss_arr+=loss\n",
        "        # np.append(loss_arr,loss,axis=0)\n",
        "        loss.backward()\n",
        "\n",
        "        # Let's update the weights\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad *1e-7\n",
        "            biass -= biass.grad * 1e-7\n",
        "            # Set the gradients to zero\n",
        "            weights.grad.zero_()\n",
        "            biass.grad.zero_()\n",
        "    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n",
        "\n",
        "for x,y in train_loader:\n",
        "  preds= model(x)\n",
        "  print(\"\\nFinal Prediction is :\\n\",preds)\n",
        "  print(\"\\nActual targets are :\\n\",y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "UzXslT3JFJRD",
        "outputId": "b7d9b980-27c4-4271-dddb-1ceb41b8ca99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.8869,  2.1758,  0.7298]], requires_grad=True)\n",
            "tensor([-0.4235], requires_grad=True)\n",
            "Prediction is :\n",
            " tensor([[169.3093],\n",
            "        [-72.3196],\n",
            "        [ 38.9979],\n",
            "        [129.3491]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[119.],\n",
            "        [ 22.],\n",
            "        [ 56.],\n",
            "        [103.]])\n",
            "Prediction is :\n",
            " tensor([[ 38.9979],\n",
            "        [-72.3196],\n",
            "        [169.3093],\n",
            "        [ 66.0527]], grad_fn=<AddBackward0>)\n",
            "\n",
            "Actual targets is :\n",
            " tensor([[ 56.],\n",
            "        [ 22.],\n",
            "        [119.],\n",
            "        [ 81.]])\n",
            "\n",
            "Loss is:  tensor(2984.9272, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5e99b0430f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;31m# np.append(loss_arr,loss,axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;31m# See gh-54457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration over a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_arr)"
      ],
      "metadata": {
        "id": "OcQQaeIFFKPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1635749f-6f25-4efc-f6c8-d5a80a159797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "MSE = mse_loss(preds,y)\n",
        "print(\"MSE: \",MSE)\n",
        "\n",
        "print(\"Weights: \",weights)\n",
        "print(\"Bias: \",biass)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLpENqbMFLdU",
        "outputId": "58062aeb-45af-4fe7-b3d1-4568360a7840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  tensor(2525.7390, grad_fn=<DivBackward0>)\n",
            "Weights:  tensor([[-1.8869,  2.1758,  0.7298]], requires_grad=True)\n",
            "Bias:  tensor([-0.4235], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "history = model.fit(X_train, y_train)\n",
        "print(history)\n",
        "# loss_train = history['train_loss']\n",
        "# epochs = range(1,1000)\n",
        "# plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "# plt.title('Training loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QJwi_HNFNDu",
        "outputId": "91a9e2cd-358b-4ca1-849c-4262922b46e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4_1"
      ],
      "metadata": {
        "id": "-2Db1I_CH8SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37],[69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69,96, 70],\n",
        "                   [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96,70]], dtype='float32')\n",
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],\n",
        "[56, 70], [81, 101], [119, 133], [22, 37], [103, 119]],dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs,targets)\n",
        "\n",
        "# Define data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))\n",
        "\n",
        "# Define model\n",
        "model = nn.Linear(3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjHfBDNLH9tD",
        "outputId": "5605baa8-ce93-41e5-e094-282cf1765872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.5189,  0.1947, -0.2904],\n",
            "        [-0.0798, -0.3647,  0.0358]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2055, -0.2495], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "BX12ke_cH-5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3gHj-iIAF_",
        "outputId": "3b26c72c-ea54-4d23-87d2-30f8ddcfba4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16765.0957, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            # Generate predictions\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            # Perform gradient descent\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "    print('Training loss: ', loss_fn(model(inputs), targets))\n",
        "\n",
        "# Train the model for 100 epochs\n",
        "fit(100, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWzaROlaIA-g",
        "outputId": "26a49611-e246-4cfb-82b2-e3eb8b5f71ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  tensor(23.7071, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ52T-6HICKS",
        "outputId": "53fd4d92-4080-4363-c7ce-de443a86cdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.0238,  71.6338],\n",
              "        [ 79.4021,  99.3211],\n",
              "        [123.8609, 133.6501],\n",
              "        [ 25.7914,  44.9240],\n",
              "        [ 94.2406, 112.1449],\n",
              "        [ 58.0238,  71.6338],\n",
              "        [ 79.4021,  99.3211],\n",
              "        [123.8609, 133.6501],\n",
              "        [ 25.7914,  44.9240],\n",
              "        [ 94.2406, 112.1449],\n",
              "        [ 58.0238,  71.6338],\n",
              "        [ 79.4021,  99.3211],\n",
              "        [123.8609, 133.6501],\n",
              "        [ 25.7914,  44.9240],\n",
              "        [ 94.2406, 112.1449]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with targets\n",
        "targets\n",
        "\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx4UPP1EIDMH",
        "outputId": "503f4503-c03a-4926-858d-9ca577fa2ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit(100, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX8EIUXzIEPB",
        "outputId": "4b68cb2a-71f6-4be6-8376-6d2bc8edfd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  tensor(9.4001, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1:\n",
        "Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)."
      ],
      "metadata": {
        "id": "rHJQTz9zIFar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "nx4oksKiILa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression():\n",
        "    def __init__(self):\n",
        "        self.b0 = 0\n",
        "        self.b1 = 0\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        mean_x = np.mean(X)\n",
        "        mean_y = np.mean(y)\n",
        "        \n",
        "        SSxy = np.sum(np.multiply(X, y)) - len(x) * mean_x * mean_y\n",
        "        SSxx = np.sum(np.multiply(X, x)) - len(x) * mean_x * mean_x\n",
        "        \n",
        "        self.b1 = SSxy / SSxx\n",
        "        self.b0 = mean_y - self.b1 * mean_x\n",
        "    \n",
        "    def predict(self, input_data):\n",
        "        return self.b0 + self.b1 * input_data"
      ],
      "metadata": {
        "id": "woHtDGV6IMxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "y = np.array([6, 6, 11, 17, 16, 20, 23, 23, 29, 33, 39])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)"
      ],
      "metadata": {
        "id": "TYq5JB1eINt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x)\n",
        "plt.scatter(x = x, y = y, color='orange')\n",
        "plt.plot(predictions, color='orange')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f9w6x_2tIOng",
        "outputId": "a03baee6-0504-4eb8-d7af-ab1fd41b42bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2\n",
        "Try Linear regression on same prediction data using Tensorflow."
      ],
      "metadata": {
        "id": "rwMqbsrgIPjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(101)\n",
        "tf.random.set_seed(101)"
      ],
      "metadata": {
        "id": "nTXRsNN4IUl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating random linear data\n",
        "# There will be 50 data points ranging from 0 to 50\n",
        "\n",
        "# x = np.linspace(0, 50, 50)\n",
        "# y = np.linspace(0, 50, 50)\n",
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "y = np.array([6, 6, 11, 17, 16, 20, 23, 23, 29, 33, 39])\n",
        " \n",
        "# Adding noise to the random linear data\n",
        "# x += np.random.uniform(-4, 4, 50)\n",
        "# y += np.random.uniform(-4, 4, 50)\n",
        " \n",
        "n = len(x) # Number of data points"
      ],
      "metadata": {
        "id": "XANlpwhwITyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot of Training Data\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title(\"Training Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jzspLIBRIZ3A",
        "outputId": "ed09ad69-114a-4834-8ffb-7ef3822b378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall tensorflow-gpu tensorflow tensorflow-base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvyavFYpIatn",
        "outputId": "74425959-72d4-4655-dfa2-56b96ee7053b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: tensorflow 2.11.0\n",
            "Uninstalling tensorflow-2.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.8/dist-packages/tensorflow-2.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.11.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-base as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "Ir0V4taAIb3x",
        "outputId": "cbc8d196-09a7-441e-fc07-701fcdfac429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "X = tf.compat.v1.placeholder(\"float\")\n",
        "Y = tf.compat.v1.placeholder(\"float\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eOaaToPIlfl",
        "outputId": "1d7de68e-be47-42a7-cb58-c6311b9e0156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = tf.Variable(np.random.randn(), name = \"W\")\n",
        "b = tf.Variable(np.random.randn(), name = \"b\")\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 1000\n",
        "\n",
        "# Hypothesis\n",
        "y_pred = tf.add(tf.multiply(X, W), b)\n",
        " \n",
        "# Mean Squared Error Cost Function\n",
        "cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n",
        " \n",
        "# Gradient Descent Optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        " \n",
        "# Global Variables Initializer\n",
        "init = tf.global_variables_initializer()"
      ],
      "metadata": {
        "id": "XcbqBJc-In-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the Tensorflow Session\n",
        "with tf.Session() as sess:\n",
        "     \n",
        "    # Initializing the Variables\n",
        "    sess.run(init)\n",
        "     \n",
        "    # Iterating through all the epochs\n",
        "    for epoch in range(training_epochs):\n",
        "         \n",
        "        # Feeding each data point into the optimizer using Feed Dictionary\n",
        "        for (_x, _y) in zip(x, y):\n",
        "            sess.run(optimizer, feed_dict = {X : _x, Y : _y})\n",
        "         \n",
        "        # Displaying the result after every 50 epochs\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            # Calculating the cost a every epoch\n",
        "            c = sess.run(cost, feed_dict = {X : x, Y : y})\n",
        "            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
        "     \n",
        "    # Storing necessary values to be used outside the Session\n",
        "    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\n",
        "    weight = sess.run(W)\n",
        "    bias = sess.run(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pUqEqt4Io92",
        "outputId": "d674bf7c-c90d-4398-96eb-4f7ebe968ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 : cost = 1.7700539 W = 3.2434921 b = 0.76008624\n",
            "Epoch 100 : cost = 1.7633674 W = 3.2370675 b = 0.8118001\n",
            "Epoch 150 : cost = 1.7578653 W = 3.2312994 b = 0.8582286\n",
            "Epoch 200 : cost = 1.7533263 W = 3.2261207 b = 0.89991146\n",
            "Epoch 250 : cost = 1.749575 W = 3.2214713 b = 0.9373347\n",
            "Epoch 300 : cost = 1.7464694 W = 3.2172968 b = 0.9709321\n",
            "Epoch 350 : cost = 1.7438917 W = 3.2135494 b = 1.0010957\n",
            "Epoch 400 : cost = 1.7417483 W = 3.2101853 b = 1.028176\n",
            "Epoch 450 : cost = 1.7399601 W = 3.2071643 b = 1.0524899\n",
            "Epoch 500 : cost = 1.7384661 W = 3.2044525 b = 1.0743172\n",
            "Epoch 550 : cost = 1.7372134 W = 3.202018 b = 1.0939153\n",
            "Epoch 600 : cost = 1.7361597 W = 3.199832 b = 1.1115103\n",
            "Epoch 650 : cost = 1.7352709 W = 3.1978693 b = 1.127305\n",
            "Epoch 700 : cost = 1.7345207 W = 3.1961074 b = 1.1414874\n",
            "Epoch 750 : cost = 1.733884 W = 3.194526 b = 1.1542196\n",
            "Epoch 800 : cost = 1.7333448 W = 3.1931057 b = 1.1656507\n",
            "Epoch 850 : cost = 1.7328814 W = 3.1918304 b = 1.1759132\n",
            "Epoch 900 : cost = 1.732488 W = 3.1906857 b = 1.1851267\n",
            "Epoch 950 : cost = 1.7321489 W = 3.1896584 b = 1.1933982\n",
            "Epoch 1000 : cost = 1.7318579 W = 3.1887352 b = 1.2008244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the predictions\n",
        "predictions = weight * x + bias\n",
        "print(\"Training cost =\", training_cost, \"Weight =\", weight, \"bias =\", bias, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSCTgQcEIq5L",
        "outputId": "c150c148-663f-40ae-c146-035cf25d0ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost = 1.7318579 Weight = 3.1887352 bias = 1.2008244 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Results\n",
        "plt.plot(x, y, 'ro', label ='Original data')\n",
        "plt.plot(x, predictions, label ='Fitted line')\n",
        "plt.title('Linear Regression Result')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Y-uJH8nDIsjF",
        "outputId": "449c69d0-4178-4c21-dd13-da2d6f7de655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEX4B_a22DPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}